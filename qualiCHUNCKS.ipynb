{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.54.1-cp312-cp312-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\leo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\leo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\leo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.8 MB 2.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.6/7.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.4/7.8 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.9/7.8 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.7/7.8 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.2/7.8 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.7/7.8 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.0/7.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.8/7.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.0-cp312-cp312-win_amd64.whl (218 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\Leo\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiras linhas do dataframe\n",
      "Index(['Legal Fund Name Including Umbrella', 'Fund Code', 'Citi Code', 'ISIN',\n",
      "       'WKN', 'Apir Code', 'SEDOL', 'As Of Date', 'ESG Score', 'ESG Rating',\n",
      "       ...\n",
      "       'BIC Of Transfer Agent', 'Domicile Of Transfer Agent',\n",
      "       'Marketmaker Name', 'Dissemination Recipient',\n",
      "       'Global Intermediary Identification Number Of Fund',\n",
      "       'Sub-Investment Advisor Name', 'Auditor Name', 'Fund Promoter Name',\n",
      "       'EmailAddressOfManCoIdentifier', 'IsUNPRISignatoryIdentifier'],\n",
      "      dtype='object', length=2206)\n"
     ]
    }
   ],
   "source": [
    "print(\"primeiras linhas do dataframe\")\n",
    "\n",
    "# Definindo o tamanho do chunk para x linhas\n",
    "chunksize = 200\n",
    "reader = pd.read_csv('Quali_20240616.csv', chunksize=chunksize)\n",
    "\n",
    "# Pegando o primeiro chunk\n",
    "chunk = next(reader)\n",
    "\n",
    "# Exibindo o chunk\n",
    "print(chunk.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primeiras linhas do dataframe\n",
      "         Legal Fund Name Including Umbrella Fund Code Citi Code          ISIN  \\\n",
      "0                                      C 11     00F9A      009A  AT0000721402   \n",
      "1                                      C 11     00F9A      009A  AT0000721402   \n",
      "2                                  R-VIP 50     00F9G      009G  AT0000A0FA24   \n",
      "3                                  R-VIP 50     00F9G      009G  AT0000A0FA24   \n",
      "4                                 R-VIP 100     00F9I      009I  AT0000A0F9X2   \n",
      "5                                 R-VIP 100     00F9I      009I  AT0000A0F9X2   \n",
      "6                          Raiffeisen R 135     00F9K      009K  AT0000691365   \n",
      "7                          Raiffeisen R 135     00F9K      009K  AT0000691365   \n",
      "8  JPMorgan Funds - Europe Equity Plus Fund     AEFD9      00A2  LU0289214545   \n",
      "9  JPMorgan Funds - Europe Equity Plus Fund     AEFD9      00A2  LU0289214545   \n",
      "\n",
      "      WKN  Apir Code    SEDOL  As Of Date  ESG Score  ESG Rating  ...  \\\n",
      "0  A0J4QW        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "1  A0J4QW        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "2  A0YBNA        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "3  A0YBNA        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "4  A0YBM7        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "5  A0YBM7        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "6  A0MTVZ        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "7  A0MTVZ        NaN      NaN         NaN        NaN         NaN  ...   \n",
      "8  A0MNZ6        NaN  B1VWZB7         NaN        NaN         NaN  ...   \n",
      "9  A0MNZ6        NaN  B1VWZB7         NaN        NaN         NaN  ...   \n",
      "\n",
      "   BIC Of Transfer Agent  Domicile Of Transfer Agent  Marketmaker Name  \\\n",
      "0                    NaN                         NaN               NaN   \n",
      "1                    NaN                         NaN               NaN   \n",
      "2                    NaN                         NaN               NaN   \n",
      "3                    NaN                         NaN               NaN   \n",
      "4                    NaN                         NaN               NaN   \n",
      "5                    NaN                         NaN               NaN   \n",
      "6                    NaN                         NaN               NaN   \n",
      "7                    NaN                         NaN               NaN   \n",
      "8                    NaN                         NaN               NaN   \n",
      "9                    NaN                         NaN               NaN   \n",
      "\n",
      "   Dissemination Recipient  Global Intermediary Identification Number Of Fund  \\\n",
      "0                      NaN                                BI33Z7.99999.SL.040   \n",
      "1                      NaN                                BI33Z7.99999.SL.040   \n",
      "2                      NaN                                I5ACQV.99999.SL.040   \n",
      "3                      NaN                                I5ACQV.99999.SL.040   \n",
      "4                      NaN                                U5QQTP.99999.SL.040   \n",
      "5                      NaN                                U5QQTP.99999.SL.040   \n",
      "6                      NaN                                FKKMZQ.99999.SL.040   \n",
      "7                      NaN                                FKKMZQ.99999.SL.040   \n",
      "8                      NaN                                5SRHAW.99999.SL.442   \n",
      "9                      NaN                                5SRHAW.99999.SL.442   \n",
      "\n",
      "   Sub-Investment Advisor Name                                 Auditor Name  \\\n",
      "0                          NaN                            KPMG Austria GmbH   \n",
      "1                          NaN                            KPMG Austria GmbH   \n",
      "2                          NaN                            KPMG Austria GmbH   \n",
      "3                          NaN                            KPMG Austria GmbH   \n",
      "4                          NaN                            KPMG Austria GmbH   \n",
      "5                          NaN                            KPMG Austria GmbH   \n",
      "6                          NaN                            KPMG Austria GmbH   \n",
      "7                          NaN                            KPMG Austria GmbH   \n",
      "8                          NaN  PriceWaterhouse Coopers Société Coopérative   \n",
      "9                          NaN  PriceWaterhouse Coopers Société Coopérative   \n",
      "\n",
      "            Fund Promoter Name  EmailAddressOfManCoIdentifier  \\\n",
      "0                     Kathrein                            NaN   \n",
      "1                     Kathrein                            NaN   \n",
      "2                          NaN                            NaN   \n",
      "3                          NaN                            NaN   \n",
      "4                          NaN                            NaN   \n",
      "5                          NaN                            NaN   \n",
      "6                          NaN                            NaN   \n",
      "7                          NaN                            NaN   \n",
      "8  JPMorgan Bank Luxembourg SA                  @jpmorgan.com   \n",
      "9  JPMorgan Bank Luxembourg SA                  @jpmorgan.com   \n",
      "\n",
      "   IsUNPRISignatoryIdentifier  \n",
      "0                         NaN  \n",
      "1                         NaN  \n",
      "2                         NaN  \n",
      "3                         NaN  \n",
      "4                         NaN  \n",
      "5                         NaN  \n",
      "6                         NaN  \n",
      "7                         NaN  \n",
      "8                         Yes  \n",
      "9                         Yes  \n",
      "\n",
      "[10 rows x 2206 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"primeiras linhas do dataframe\")\n",
    "\n",
    "# Definindo o tamanho do chunk para x linhas\n",
    "chunksize = 200\n",
    "reader = pd.read_csv('Quali_20240617.csv', chunksize=chunksize)\n",
    "\n",
    "# Pegando o primeiro chunk\n",
    "chunk = next(reader)\n",
    "\n",
    "# Exibindo o chunk\n",
    "print(chunk.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Legal Fund Name Including Umbrella', 'Fund Code', 'Citi Code', 'ISIN', 'WKN', '20000_Financial_Instrument_Identifying_Data', 'EPT Portfolio Name', 'EPT Portfolio or Share Class Currency', 'EPT PRIIPs KID Publication Date', 'EPT Reference Language', 'EPT Valuation Frequency', 'EPT Summary Risk Indicator', 'EPT Is SRI Adjusted', 'EPT Market Risk Measure', 'EPT Credit Risk Measure', 'EPT Recommended Holding Period', 'EPT Number Of Observed Returns', 'EPT Reference Invested Amount', 'EPT Ongoing Costs Management Fees and Other Administrative or Operating Costs', 'EPT Portfolio Transaction Costs', 'EPT Target Market Retail Investor Type', 'EPT Investment Objective', 'EPT Risk Narrative', 'EPT Other Risk Narrative', 'EPT Investment Option', 'Portfolio Turnover Ratio', 'Portfolio Turnover Ratio Date', 'FE Group Name', 'Unit Status', 'Company Contact Address', 'Company Contact E-Mail', 'Company Contact Post Code', 'Company Contact Telephone', 'Company Contact Web Address', 'FE Fund Name', 'Sub Category', 'Main Category', 'Global Fund Classification', 'Has Performance Fee', 'Performance Fee Applied', 'Custodian Fee Applied', 'Subscription Fee Maximum', 'Redemption Fee Maximum', 'Management Fee Applied', 'Management Fee Applied Reference Date', 'Management Fee Maximum', 'TER Excluding Performance Fee', 'TER Excluding Performance Fee Date', 'TER Including Performance Fee', 'TER Including Performance Fee Date', 'Has Ongoing Charges', 'Ongoing Charges', 'Ongoing Charges Date', 'Distribution Fee', 'Has Separate Distribution Fee', 'Distribution Fee Reference Date', 'Minimal Subscription Category', 'Minimal Initial Subscription In Shares', 'Minimal Initial Subscription In Amount', 'Currency Of Minimal Subscription', 'Minimal Subsequent Subscription Category', 'Minimal Subsequent Subscription In Shares', 'Minimal Subsequent Subscription In Amount', 'Maximal Number Of Possible Decimals NAV', 'Settlement Period For Subscription', 'EFAMA Main EFC Category', 'EFAMA Active EFC Classification', 'Is EU Directive Relevant', 'Type Of EU Directive', 'UCITS Version', 'Legal Form', 'Launch Price', 'Launch Price Currency', 'Launch Price Date', 'Listing Currency', 'Valor', 'Share Class Extension', 'Full Share Class Name', 'Abbreviated Share Class Name', 'Valuation Frequency', 'Share Class Distribution Policy', 'Share Class Currency', 'Share Class Lifecycle', 'Share Class Launch Date', 'Investment Status', 'Benchmark', 'SRRI', 'Record Date For SRRI', 'CurrencyHedgeShareClassIdentifier', 'DistributionDeclarationFrequencyIdentifier', 'Asset Class', 'Sector Names', 'Fund Domicile Alpha-2', 'Legal Fund Name Only', 'Fund Launch Date', 'Investment Objective in English', 'Fund Currency', 'Open-ended Or Closed-ended Fund Structure', 'CurrencyHedgePortfolioIdentifier', 'Domicile', 'Has Umbrella', 'Umbrella', 'Domicile Of Umbrella', 'Fund Group Name', 'ManCo', 'Domicile Of ManCo', 'Fund Administrator Name', 'Custodian Bank Name', 'Portfolio Managing Company Name', 'Transfer Agent Name', 'Auditor Name', 'Fund Promoter Name', 'Exit Charge', 'Is ETF']\n"
     ]
    }
   ],
   "source": [
    "with open(\"colunas_especificas.txt\", 'r') as fin:\n",
    "    cols = fin.readlines()\n",
    "    cols_especificas = []\n",
    "    for c in cols:\n",
    "        cols_especificas.append(c.replace(\"\\n\",\"\"))\n",
    "\n",
    "\n",
    "print(cols_especificas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo as primeiras 100 linhas do arquivo Quali_20240601.csv\n",
      "As primeiras 100 linhas de Quali_20240601.csv foram processadas e armazenadas como chunk_01\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240602.csv\n",
      "As primeiras 100 linhas de Quali_20240602.csv foram processadas e armazenadas como chunk_02\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240603.csv\n",
      "As primeiras 100 linhas de Quali_20240603.csv foram processadas e armazenadas como chunk_03\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240604.csv\n",
      "As primeiras 100 linhas de Quali_20240604.csv foram processadas e armazenadas como chunk_04\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240605.csv\n",
      "As primeiras 100 linhas de Quali_20240605.csv foram processadas e armazenadas como chunk_05\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240606.csv\n",
      "As primeiras 100 linhas de Quali_20240606.csv foram processadas e armazenadas como chunk_06\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240607.csv\n",
      "As primeiras 100 linhas de Quali_20240607.csv foram processadas e armazenadas como chunk_07\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240608.csv\n",
      "As primeiras 100 linhas de Quali_20240608.csv foram processadas e armazenadas como chunk_08\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240609.csv\n",
      "As primeiras 100 linhas de Quali_20240609.csv foram processadas e armazenadas como chunk_09\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240610.csv\n",
      "As primeiras 100 linhas de Quali_20240610.csv foram processadas e armazenadas como chunk_10\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240611.csv\n",
      "As primeiras 100 linhas de Quali_20240611.csv foram processadas e armazenadas como chunk_11\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240612.csv\n",
      "As primeiras 100 linhas de Quali_20240612.csv foram processadas e armazenadas como chunk_12\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240613.csv\n",
      "As primeiras 100 linhas de Quali_20240613.csv foram processadas e armazenadas como chunk_13\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240614.csv\n",
      "As primeiras 100 linhas de Quali_20240614.csv foram processadas e armazenadas como chunk_14\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240615.csv\n",
      "As primeiras 100 linhas de Quali_20240615.csv foram processadas e armazenadas como chunk_15\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240616.csv\n",
      "As primeiras 100 linhas de Quali_20240616.csv foram processadas e armazenadas como chunk_16\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240617.csv\n",
      "As primeiras 100 linhas de Quali_20240617.csv foram processadas e armazenadas como chunk_17\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240618.csv\n",
      "As primeiras 100 linhas de Quali_20240618.csv foram processadas e armazenadas como chunk_18\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240619.csv\n",
      "As primeiras 100 linhas de Quali_20240619.csv foram processadas e armazenadas como chunk_19\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240620.csv\n",
      "As primeiras 100 linhas de Quali_20240620.csv foram processadas e armazenadas como chunk_20\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240621.csv\n",
      "As primeiras 100 linhas de Quali_20240621.csv foram processadas e armazenadas como chunk_21\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240622.csv\n",
      "As primeiras 100 linhas de Quali_20240622.csv foram processadas e armazenadas como chunk_22\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240623.csv\n",
      "As primeiras 100 linhas de Quali_20240623.csv foram processadas e armazenadas como chunk_23\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240624.csv\n",
      "As primeiras 100 linhas de Quali_20240624.csv foram processadas e armazenadas como chunk_24\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240625.csv\n",
      "As primeiras 100 linhas de Quali_20240625.csv foram processadas e armazenadas como chunk_25\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240626.csv\n",
      "As primeiras 100 linhas de Quali_20240626.csv foram processadas e armazenadas como chunk_26\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240627.csv\n",
      "As primeiras 100 linhas de Quali_20240627.csv foram processadas e armazenadas como chunk_27\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240628.csv\n",
      "As primeiras 100 linhas de Quali_20240628.csv foram processadas e armazenadas como chunk_28\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240629.csv\n",
      "As primeiras 100 linhas de Quali_20240629.csv foram processadas e armazenadas como chunk_29\n",
      "Lendo as primeiras 100 linhas do arquivo Quali_20240630.csv\n",
      "As primeiras 100 linhas de Quali_20240630.csv foram processadas e armazenadas como chunk_30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Defina o tamanho do chunk para ler as primeiras N linhas\n",
    "chunksize = 100  # Lê apenas as primeiras 100 linhas\n",
    "\n",
    "# Dicionário para armazenar os DataFrames processados\n",
    "chunks_dict = {}\n",
    "\n",
    "for xx in range(1, 31):\n",
    "    # Formatar o número com dois dígitos\n",
    "    xx_formatted = f\"{xx:02d}\"\n",
    "    filename = f\"Quali_202406{xx_formatted}.csv\"\n",
    "    \n",
    "    print(f\"Lendo as primeiras {chunksize} linhas do arquivo {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Criar um leitor de chunks para o arquivo atual\n",
    "        reader = pd.read_csv(filename, chunksize=chunksize)\n",
    "        \n",
    "        # Obter o primeiro chunk\n",
    "        chunk = next(reader)\n",
    "        \n",
    "        # Verificar quais colunas estão presentes no chunk\n",
    "        cols_to_keep = [col for col in cols_especificas if col in chunk.columns]\n",
    "        \n",
    "        # Se nenhuma coluna for encontrada, pular o arquivo\n",
    "        if not cols_to_keep:\n",
    "            print(f\"Nenhuma das colunas especificadas foi encontrada em {filename}\")\n",
    "            continue\n",
    "        \n",
    "        # Filtrar as colunas específicas\n",
    "        chunk_filtered = chunk[cols_to_keep]\n",
    "        \n",
    "        # Armazenar o chunk filtrado no dicionário\n",
    "        chunks_dict[f\"chunk_{xx_formatted}\"] = chunk_filtered\n",
    "        \n",
    "        print(f\"As primeiras {chunksize} linhas de {filename} foram processadas e armazenadas como chunk_{xx_formatted}\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"O arquivo {filename} não foi encontrado. Pulando para o próximo arquivo.\")\n",
    "        continue\n",
    "\n",
    "# Agora você pode acessar cada DataFrame processado a partir do dicionário 'chunks_dict'\n",
    "# Por exemplo:\n",
    "# df_chunk_01 = chunks_dict['chunk_01']\n",
    "# print(df_chunk_01.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Legal Fund Name Including Umbrella Fund Code Citi Code          ISIN  \\\n",
      "0                               C 11     00F9A      009A  AT0000721402   \n",
      "1                               C 11     00F9A      009A  AT0000721402   \n",
      "2                           R-VIP 50     00F9G      009G  AT0000A0FA24   \n",
      "3                           R-VIP 50     00F9G      009G  AT0000A0FA24   \n",
      "4                          R-VIP 100     00F9I      009I  AT0000A0F9X2   \n",
      "\n",
      "      WKN 20000_Financial_Instrument_Identifying_Data EPT Portfolio Name  \\\n",
      "0  A0J4QW                                AT0000721402             C 11 A   \n",
      "1  A0J4QW                                         NaN             C 11 A   \n",
      "2  A0YBNA                                AT0000A0FA24         R-VIP 50 T   \n",
      "3  A0YBNA                                         NaN         R-VIP 50 T   \n",
      "4  A0YBM7                                AT0000A0F9X2    R-VIP 100 (R) T   \n",
      "\n",
      "  EPT Portfolio or Share Class Currency EPT PRIIPs KID Publication Date  \\\n",
      "0                                   EUR                      2024-04-30   \n",
      "1                                   EUR                      2024-04-30   \n",
      "2                                   EUR                      2024-04-30   \n",
      "3                                   EUR                      2024-04-30   \n",
      "4                                   EUR                      2024-04-30   \n",
      "\n",
      "  EPT Reference Language  ...                                           ManCo  \\\n",
      "0                    deu  ...  Raiffeisen Kapitalanlage-Gesellschaft m. b. H.   \n",
      "1                    deu  ...  Raiffeisen Kapitalanlage-Gesellschaft m. b. H.   \n",
      "2                    deu  ...  Raiffeisen Kapitalanlage-Gesellschaft m. b. H.   \n",
      "3                    deu  ...  Raiffeisen Kapitalanlage-Gesellschaft m. b. H.   \n",
      "4                    deu  ...  Raiffeisen Kapitalanlage-Gesellschaft m. b. H.   \n",
      "\n",
      "   Domicile Of ManCo Fund Administrator Name  \\\n",
      "0                 AT                     NaN   \n",
      "1                 AT                     NaN   \n",
      "2                 AT                     NaN   \n",
      "3                 AT                     NaN   \n",
      "4                 AT                     NaN   \n",
      "\n",
      "                Custodian Bank Name  \\\n",
      "0  Raiffeisen Bank International AG   \n",
      "1  Raiffeisen Bank International AG   \n",
      "2  Raiffeisen Bank International AG   \n",
      "3  Raiffeisen Bank International AG   \n",
      "4  Raiffeisen Bank International AG   \n",
      "\n",
      "                Portfolio Managing Company Name  \\\n",
      "0        Kathrein Privatbank Aktiengesellschaft   \n",
      "1        Kathrein Privatbank Aktiengesellschaft   \n",
      "2  Raiffeisen Kapitalanlage-Gesellschaft m.b.H.   \n",
      "3  Raiffeisen Kapitalanlage-Gesellschaft m.b.H.   \n",
      "4  Raiffeisen Kapitalanlage-Gesellschaft m.b.H.   \n",
      "\n",
      "                        Transfer Agent Name       Auditor Name  \\\n",
      "0  Raiffeisen Bank International AG, Vienna  KPMG Austria GmbH   \n",
      "1  Raiffeisen Bank International AG, Vienna  KPMG Austria GmbH   \n",
      "2  Raiffeisen Bank International AG, Vienna  KPMG Austria GmbH   \n",
      "3  Raiffeisen Bank International AG, Vienna  KPMG Austria GmbH   \n",
      "4  Raiffeisen Bank International AG, Vienna  KPMG Austria GmbH   \n",
      "\n",
      "   Fund Promoter Name  Exit Charge  Is ETF  \n",
      "0            Kathrein          NaN      No  \n",
      "1            Kathrein          NaN      No  \n",
      "2                 NaN          NaN      No  \n",
      "3                 NaN          NaN      No  \n",
      "4                 NaN          NaN      No  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "df_chunk_01 = chunks_dict['chunk_01']\n",
    "print(df_chunk_01.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ISIN Citi Code EPT Reference Language  \\\n",
      "0     AT0000691365      009K                    deu   \n",
      "1     AT0000691365      009K                    deu   \n",
      "2     AT0000691365      009K                    deu   \n",
      "3     AT0000691365      009K                    deu   \n",
      "4     AT0000691365      009K                    deu   \n",
      "...            ...       ...                    ...   \n",
      "1058  LU0638090042      00FZ                    swe   \n",
      "1059  LU0638090042      00FZ                    swe   \n",
      "1060  LU0638090042      00FZ                    swe   \n",
      "1061  LU0638090042      00FZ                    swe   \n",
      "1062  LU0638090042      00FZ                    swe   \n",
      "\n",
      "                                            campo  \\\n",
      "0     20000_Financial_Instrument_Identifying_Data   \n",
      "1     20000_Financial_Instrument_Identifying_Data   \n",
      "2     20000_Financial_Instrument_Identifying_Data   \n",
      "3     20000_Financial_Instrument_Identifying_Data   \n",
      "4     20000_Financial_Instrument_Identifying_Data   \n",
      "...                                           ...   \n",
      "1058              EPT Portfolio Transaction Costs   \n",
      "1059                          Custodian Bank Name   \n",
      "1060              EPT PRIIPs KID Publication Date   \n",
      "1061              EPT Portfolio Transaction Costs   \n",
      "1062                          Custodian Bank Name   \n",
      "\n",
      "                           valor_antigo                         valor_novo  \\\n",
      "0                          AT0000691365                                NaN   \n",
      "1                                   NaN                       AT0000691365   \n",
      "2                          AT0000691365                                NaN   \n",
      "3                                   NaN                       AT0000691365   \n",
      "4                          AT0000691365                                NaN   \n",
      "...                                 ...                                ...   \n",
      "1058                           0.002708                           0.002542   \n",
      "1059  J.P. Morgan SE, Luxembourg Branch  J.P. MORGAN SE, LUXEMBOURG BRANCH   \n",
      "1060                         2024-04-30                         2024-05-31   \n",
      "1061                           0.002542                           0.002589   \n",
      "1062  J.P. MORGAN SE, LUXEMBOURG BRANCH  J.P. Morgan SE, Luxembourg Branch   \n",
      "\n",
      "      data  \n",
      "0        1  \n",
      "1        2  \n",
      "2        2  \n",
      "3        3  \n",
      "4        3  \n",
      "...    ...  \n",
      "1058     3  \n",
      "1059    25  \n",
      "1060    27  \n",
      "1061    27  \n",
      "1062    29  \n",
      "\n",
      "[1063 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que você já tem o dicionário 'chunks_dict' com os DataFrames para cada dia\n",
    "# E que as colunas identificadoras são 'ISIN', 'Citi Code', 'EPT Reference Language'\n",
    "\n",
    "# Lista para armazenar os DataFrames com a coluna 'data' adicionada\n",
    "dfs_with_date = []\n",
    "\n",
    "for xx in range(1, 31):\n",
    "    xx_formatted = f\"{xx:02d}\"\n",
    "    key = f\"chunk_{xx_formatted}\"\n",
    "    if key in chunks_dict:\n",
    "        df = chunks_dict[key].copy()\n",
    "        df['data'] = int(xx)  # Adiciona a coluna 'data' com o valor do dia\n",
    "        dfs_with_date.append(df)\n",
    "\n",
    "# Combina todos os DataFrames em um único DataFrame\n",
    "combined_df = pd.concat(dfs_with_date, ignore_index=True)\n",
    "\n",
    "# Ordena o DataFrame pelos identificadores e pela data\n",
    "combined_df.sort_values(by=['ISIN', 'Citi Code', 'EPT Reference Language', 'data'], inplace=True)\n",
    "\n",
    "# Lista para armazenar as mudanças detectadas\n",
    "changes = []\n",
    "\n",
    "# Definir as colunas identificadoras e as colunas a serem comparadas\n",
    "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
    "value_cols = [col for col in combined_df.columns if col not in id_cols + ['data']]\n",
    "\n",
    "# Agrupa o DataFrame pelos identificadores\n",
    "grouped = combined_df.groupby(id_cols)\n",
    "\n",
    "for name, group in grouped:\n",
    "    group = group.sort_values(by='data')\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(1, len(group)):\n",
    "        current_row = group.loc[i]\n",
    "        previous_row = group.loc[i-1]\n",
    "        data_current = current_row['data']\n",
    "        data_previous = previous_row['data']\n",
    "        for col in value_cols:\n",
    "            value_current = current_row[col]\n",
    "            value_previous = previous_row[col]\n",
    "            # Verifica se os valores são diferentes, considerando valores nulos\n",
    "            if pd.isnull(value_current) and pd.isnull(value_previous):\n",
    "                continue  # Ambos são nulos, não há mudança\n",
    "            elif value_current != value_previous:\n",
    "                changes.append({\n",
    "                    'ISIN': current_row['ISIN'],\n",
    "                    'Citi Code': current_row['Citi Code'],\n",
    "                    'EPT Reference Language': current_row['EPT Reference Language'],\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current\n",
    "                })\n",
    "\n",
    "# Cria um DataFrame com as mudanças\n",
    "changes_df = pd.DataFrame(changes)\n",
    "\n",
    "# Exibe o DataFrame com as mudanças\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            campo  \\\n",
      "0     20000_Financial_Instrument_Identifying_Data   \n",
      "1     20000_Financial_Instrument_Identifying_Data   \n",
      "2     20000_Financial_Instrument_Identifying_Data   \n",
      "3     20000_Financial_Instrument_Identifying_Data   \n",
      "4     20000_Financial_Instrument_Identifying_Data   \n",
      "...                                           ...   \n",
      "1058              EPT Portfolio Transaction Costs   \n",
      "1059                          Custodian Bank Name   \n",
      "1060              EPT PRIIPs KID Publication Date   \n",
      "1061              EPT Portfolio Transaction Costs   \n",
      "1062                          Custodian Bank Name   \n",
      "\n",
      "                           valor_antigo                         valor_novo  \\\n",
      "0                          AT0000691365                                NaN   \n",
      "1                                   NaN                       AT0000691365   \n",
      "2                          AT0000691365                                NaN   \n",
      "3                                   NaN                       AT0000691365   \n",
      "4                          AT0000691365                                NaN   \n",
      "...                                 ...                                ...   \n",
      "1058                           0.002708                           0.002542   \n",
      "1059  J.P. Morgan SE, Luxembourg Branch  J.P. MORGAN SE, LUXEMBOURG BRANCH   \n",
      "1060                         2024-04-30                         2024-05-31   \n",
      "1061                           0.002542                           0.002589   \n",
      "1062  J.P. MORGAN SE, LUXEMBOURG BRANCH  J.P. Morgan SE, Luxembourg Branch   \n",
      "\n",
      "      data  \n",
      "0        1  \n",
      "1        2  \n",
      "2        2  \n",
      "3        3  \n",
      "4        3  \n",
      "...    ...  \n",
      "1058     3  \n",
      "1059    25  \n",
      "1060    27  \n",
      "1061    27  \n",
      "1062    29  \n",
      "\n",
      "[1063 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seleciona apenas as colunas desejadas e imprime o DataFrame\n",
    "print(changes_df[['campo', 'valor_antigo', 'valor_novo', 'data']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            campo  \\\n",
      "0     20000_Financial_Instrument_Identifying_Data   \n",
      "1     20000_Financial_Instrument_Identifying_Data   \n",
      "2     20000_Financial_Instrument_Identifying_Data   \n",
      "3     20000_Financial_Instrument_Identifying_Data   \n",
      "4     20000_Financial_Instrument_Identifying_Data   \n",
      "...                                           ...   \n",
      "1058              EPT Portfolio Transaction Costs   \n",
      "1059                          Custodian Bank Name   \n",
      "1060              EPT PRIIPs KID Publication Date   \n",
      "1061              EPT Portfolio Transaction Costs   \n",
      "1062                          Custodian Bank Name   \n",
      "\n",
      "                           valor_antigo                         valor_novo  \\\n",
      "0                          AT0000691365                                NaN   \n",
      "1                                   NaN                       AT0000691365   \n",
      "2                          AT0000691365                                NaN   \n",
      "3                                   NaN                       AT0000691365   \n",
      "4                          AT0000691365                                NaN   \n",
      "...                                 ...                                ...   \n",
      "1058                           0.002708                           0.002542   \n",
      "1059  J.P. Morgan SE, Luxembourg Branch  J.P. MORGAN SE, LUXEMBOURG BRANCH   \n",
      "1060                         2024-04-30                         2024-05-31   \n",
      "1061                           0.002542                           0.002589   \n",
      "1062  J.P. MORGAN SE, LUXEMBOURG BRANCH  J.P. Morgan SE, Luxembourg Branch   \n",
      "\n",
      "            data  \n",
      "0     01/06/2024  \n",
      "1     02/06/2024  \n",
      "2     02/06/2024  \n",
      "3     03/06/2024  \n",
      "4     03/06/2024  \n",
      "...          ...  \n",
      "1058  03/06/2024  \n",
      "1059  25/06/2024  \n",
      "1060  27/06/2024  \n",
      "1061  27/06/2024  \n",
      "1062  29/06/2024  \n",
      "\n",
      "[1063 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que você já tem o dicionário 'chunks_dict' com os DataFrames para cada dia\n",
    "# E que as colunas identificadoras são 'ISIN', 'Citi Code', 'EPT Reference Language'\n",
    "\n",
    "# Lista para armazenar os DataFrames com a coluna 'data' adicionada\n",
    "dfs_with_date = []\n",
    "\n",
    "for xx in range(1, 31):\n",
    "    xx_formatted = f\"{xx:02d}\"\n",
    "    key = f\"chunk_{xx_formatted}\"\n",
    "    if key in chunks_dict:\n",
    "        df = chunks_dict[key].copy()\n",
    "        # Adiciona a coluna 'data' com o valor do dia no formato 'xx/06/2024'\n",
    "        df['data'] = f\"{xx_formatted}/06/2024\"\n",
    "        dfs_with_date.append(df)\n",
    "\n",
    "# Combina todos os DataFrames em um único DataFrame\n",
    "combined_df = pd.concat(dfs_with_date, ignore_index=True)\n",
    "\n",
    "# Converter a coluna 'data' para datetime para facilitar a ordenação\n",
    "combined_df['data'] = pd.to_datetime(combined_df['data'], format='%d/%m/%Y')\n",
    "\n",
    "# Ordena o DataFrame pelos identificadores e pela data\n",
    "combined_df.sort_values(by=['ISIN', 'Citi Code', 'EPT Reference Language', 'data'], inplace=True)\n",
    "\n",
    "# Lista para armazenar as mudanças detectadas\n",
    "changes = []\n",
    "\n",
    "# Definir as colunas identificadoras e as colunas a serem comparadas\n",
    "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
    "value_cols = [col for col in combined_df.columns if col not in id_cols + ['data']]\n",
    "\n",
    "# Agrupa o DataFrame pelos identificadores\n",
    "grouped = combined_df.groupby(id_cols)\n",
    "\n",
    "for name, group in grouped:\n",
    "    group = group.sort_values(by='data')\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(1, len(group)):\n",
    "        current_row = group.loc[i]\n",
    "        previous_row = group.loc[i-1]\n",
    "        data_current = current_row['data'].strftime('%d/%m/%Y')  # Converte para string no formato desejado\n",
    "        data_previous = previous_row['data'].strftime('%d/%m/%Y')\n",
    "        for col in value_cols:\n",
    "            value_current = current_row[col]\n",
    "            value_previous = previous_row[col]\n",
    "            # Verifica se os valores são diferentes, considerando valores nulos\n",
    "            if pd.isnull(value_current) and pd.isnull(value_previous):\n",
    "                continue  # Ambos são nulos, não há mudança\n",
    "            elif pd.isnull(value_current) != pd.isnull(value_previous):\n",
    "                # Um valor é nulo e o outro não\n",
    "                changes.append({\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current\n",
    "                })\n",
    "            elif value_current != value_previous:\n",
    "                changes.append({\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current\n",
    "                })\n",
    "\n",
    "# Cria um DataFrame com as mudanças\n",
    "changes_df = pd.DataFrame(changes)\n",
    "\n",
    "# Seleciona apenas as colunas desejadas\n",
    "changes_df = changes_df[['campo', 'valor_antigo', 'valor_novo', 'data']]\n",
    "\n",
    "# Exibe o DataFrame com as mudanças\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           campo  valor_antigo    valor_novo  \\\n",
      "0    20000_Financial_Instrument_Identifying_Data  AT0000691365           NaN   \n",
      "149  20000_Financial_Instrument_Identifying_Data  AT0000721402           NaN   \n",
      "411  20000_Financial_Instrument_Identifying_Data  AT0000A0FA24           NaN   \n",
      "321  20000_Financial_Instrument_Identifying_Data  AT0000A0F9X2           NaN   \n",
      "523  20000_Financial_Instrument_Identifying_Data  IE00B61TKZ25           NaN   \n",
      "..                                           ...           ...           ...   \n",
      "54   20000_Financial_Instrument_Identifying_Data           NaN  AT0000691365   \n",
      "203  20000_Financial_Instrument_Identifying_Data           NaN  AT0000721402   \n",
      "584  20000_Financial_Instrument_Identifying_Data  IE00B61TKZ25           NaN   \n",
      "261  20000_Financial_Instrument_Identifying_Data  AT0000779392           NaN   \n",
      "583  20000_Financial_Instrument_Identifying_Data           NaN  IE00B61TKZ25   \n",
      "\n",
      "           data  \n",
      "0    01/06/2024  \n",
      "149  01/06/2024  \n",
      "411  01/06/2024  \n",
      "321  01/06/2024  \n",
      "523  01/06/2024  \n",
      "..          ...  \n",
      "54   30/06/2024  \n",
      "203  30/06/2024  \n",
      "584  30/06/2024  \n",
      "261  30/06/2024  \n",
      "583  30/06/2024  \n",
      "\n",
      "[1063 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supondo que você já tem o dicionário 'chunks_dict' com os DataFrames para cada dia\n",
    "# E que as colunas identificadoras são 'ISIN', 'Citi Code', 'EPT Reference Language'\n",
    "\n",
    "# Lista para armazenar os DataFrames com a coluna 'data' adicionada\n",
    "dfs_with_date = []\n",
    "\n",
    "for xx in range(1, 31):\n",
    "    xx_formatted = f\"{xx:02d}\"\n",
    "    key = f\"chunk_{xx_formatted}\"\n",
    "    if key in chunks_dict:\n",
    "        df = chunks_dict[key].copy()\n",
    "        # Adiciona a coluna 'data' com o valor do dia no formato 'xx/06/2024'\n",
    "        df['data'] = f\"{xx_formatted}/06/2024\"\n",
    "        dfs_with_date.append(df)\n",
    "\n",
    "# Combina todos os DataFrames em um único DataFrame\n",
    "combined_df = pd.concat(dfs_with_date, ignore_index=True)\n",
    "\n",
    "# Converter a coluna 'data' para datetime para facilitar a ordenação\n",
    "combined_df['data'] = pd.to_datetime(combined_df['data'], format='%d/%m/%Y')\n",
    "\n",
    "# Ordena o DataFrame pelos identificadores e pela data\n",
    "combined_df.sort_values(by=['ISIN', 'Citi Code', 'EPT Reference Language', 'data'], inplace=True)\n",
    "\n",
    "# Lista para armazenar as mudanças detectadas\n",
    "changes = []\n",
    "\n",
    "# Definir as colunas identificadoras e as colunas a serem comparadas\n",
    "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
    "value_cols = [col for col in combined_df.columns if col not in id_cols + ['data']]\n",
    "\n",
    "# Agrupa o DataFrame pelos identificadores\n",
    "grouped = combined_df.groupby(id_cols)\n",
    "\n",
    "for name, group in grouped:\n",
    "    group = group.sort_values(by='data')\n",
    "    group = group.reset_index(drop=True)\n",
    "    for i in range(1, len(group)):\n",
    "        current_row = group.loc[i]\n",
    "        previous_row = group.loc[i-1]\n",
    "        data_current = current_row['data'].strftime('%d/%m/%Y')  # Converte para string no formato desejado\n",
    "        data_previous = previous_row['data'].strftime('%d/%m/%Y')\n",
    "        for col in value_cols:\n",
    "            value_current = current_row[col]\n",
    "            value_previous = previous_row[col]\n",
    "            # Verifica se os valores são diferentes, considerando valores nulos\n",
    "            if pd.isnull(value_current) and pd.isnull(value_previous):\n",
    "                continue  # Ambos são nulos, não há mudança\n",
    "            elif pd.isnull(value_current) != pd.isnull(value_previous):\n",
    "                # Um valor é nulo e o outro não\n",
    "                changes.append({\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current\n",
    "                })\n",
    "            elif value_current != value_previous:\n",
    "                changes.append({\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current\n",
    "                })\n",
    "\n",
    "# Cria um DataFrame com as mudanças\n",
    "changes_df = pd.DataFrame(changes)\n",
    "\n",
    "# Seleciona apenas as colunas desejadas\n",
    "changes_df = changes_df[['campo', 'valor_antigo', 'valor_novo', 'data']]\n",
    "\n",
    "# Converter a coluna 'data' para datetime para ordenação\n",
    "changes_df['data'] = pd.to_datetime(changes_df['data'], format='%d/%m/%Y')\n",
    "\n",
    "# Ordena o DataFrame 'changes_df' pela coluna 'data'\n",
    "changes_df.sort_values(by='data', inplace=True)\n",
    "\n",
    "# Opcional: Converte a coluna 'data' de volta para string no formato desejado\n",
    "changes_df['data'] = changes_df['data'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Exibe o DataFrame com as mudanças ordenadas por data\n",
    "print(changes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            data\n",
      "0     01/06/2024\n",
      "1     02/06/2024\n",
      "2     02/06/2024\n",
      "3     03/06/2024\n",
      "4     03/06/2024\n",
      "...          ...\n",
      "1058  03/06/2024\n",
      "1059  25/06/2024\n",
      "1060  27/06/2024\n",
      "1061  27/06/2024\n",
      "1062  29/06/2024\n",
      "\n",
      "[1063 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(changes_df[['data']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
