{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "_1E3w06w2KBU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "primeiras linhas do dataframe\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Vini\\AppData\\Local\\Temp\\ipykernel_29612\\2848425142.py:8: DtypeWarning: Columns (5,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,103,104,107,110,111,112,113,114,115,116,117,118,120,121,122,124,125,127,128,129,130,131,138,139,140,142,149,158,159,160,163,164,173,174,175,176,177,178,181,182,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264,268,272,276,280,284,288,292,296,300,304,308,312,316,320,324,328,332,336,340,344,348,352,356,360,364,368,372,376,380,384,388,392,396,400,404,408,412,416,420,424,428,432,436,440,444,448,452,456,460,464,468,472,476,480,484,488,492,496,500,504,508,512,516,520,524,528,532,536,539,540,541,542,544,545,546,549,550,553,554,557,558,560,561,562,564,567,568,569,572,573,576,577,580,581,583,586,587,588,591,592,595,596,598,599,601,602,603,605,608,609,610,612,615,616,617,620,621,624,625,628,629,631,632,633,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,655,656,657,658,802,883,884,885,888,890,892,895,897,898,899,900,902,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,935,936,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,958,959,960,961,964,966,983,1088,1090,1094,1095,1117,1119,1121,1128,1130,1132,1133,1134,1152,1155,1187,1191,1192,1195,1197,1198,1218,1219,1221,1232,1234,1237,1241,1248,1250,1253,1259,1260,1302,1303,1304,1308,1309,1317,1323,1324,1325,1327,1328,1329,1330,1331,1333,1340,1342,1345,1347,1351,1372,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1394,1395,1416,1417,1420,1425,1426,1428,1430,1432,1434,1439,1442,1446,1447,1449,1452,1453,1455,1461,1462,1463,1467,1469,1475,1476,1477,1478,1479,1481,1482,1484,1485,1486,1487,1489,1490,1492,1493,1494,1496,1497,1499,1500,1501,1504,1507,1508,1511,1513,1514,1518,1521,1525,1530,1539,1540,1541,1542,1543,1545,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1560,1562,1567,1571,1572,1573,1574,1575,1576,1577,1578,1579,1581,1584,1587,1593,1595,1602,1604,1605,1610,1612,1615,1616,1618,1620,1625,1630,1631,1635,1637,1640,1644,1647,1656,1898,1899,1902,1903,1904,1905,1906,1907,1908,1909,1910,1922,1925,1926,1927,1928,1929,1930,1933,1947,1963,1964,1968,1975,1977,2000,2008,2027,2033,2034,2035,2054,2063,2065,2078,2079,2081,2082,2083,2096,2097,2098,2099,2108,2115,2116,2121,2132,2139,2141,2142,2143,2147,2148,2149,2165,2166,2169,2171,2194,2201,2204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  chunk = next(reader)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Legal Fund Name Including Umbrella Fund Code Citi Code          ISIN  \\\n",
            "0                                      C 11     00F9A      009A  AT0000721402   \n",
            "1                                      C 11     00F9A      009A  AT0000721402   \n",
            "2                                  R-VIP 50     00F9G      009G  AT0000A0FA24   \n",
            "3                                  R-VIP 50     00F9G      009G  AT0000A0FA24   \n",
            "4                                 R-VIP 100     00F9I      009I  AT0000A0F9X2   \n",
            "...                                     ...       ...       ...           ...   \n",
            "1995     Nordea 1 - US High Yield Bond Fund     DGFZ9      05SN  LU0607988697   \n",
            "1996     Nordea 1 - US High Yield Bond Fund     DGFZ9      05SN  LU0607988697   \n",
            "1997  BlackRock Advantage Australian Equity     05FUJ      05UJ  AU60BAR08143   \n",
            "1998       BlackRock Diversified ESG Stable     05FUK      05UK  AU60BAR08119   \n",
            "1999  BlackRock Diversified ESG Growth Fund     05FUL      05UL  AU60BAR08135   \n",
            "\n",
            "         WKN  Apir Code    SEDOL  As Of Date  ESG Score  ESG Rating  ...  \\\n",
            "0     A0J4QW        NaN      NaN         NaN        NaN         NaN  ...   \n",
            "1     A0J4QW        NaN      NaN         NaN        NaN         NaN  ...   \n",
            "2     A0YBNA        NaN      NaN         NaN        NaN         NaN  ...   \n",
            "3     A0YBNA        NaN      NaN         NaN        NaN         NaN  ...   \n",
            "4     A0YBM7        NaN      NaN         NaN        NaN         NaN  ...   \n",
            "...      ...        ...      ...         ...        ...         ...  ...   \n",
            "1995  A1JHT0        NaN  B3VJ4S2         NaN        NaN         NaN  ...   \n",
            "1996  A1JHT0        NaN  B3VJ4S2         NaN        NaN         NaN  ...   \n",
            "1997     NaN  BAR0814AU      NaN         NaN        NaN         NaN  ...   \n",
            "1998     NaN  BAR0811AU      NaN         NaN        NaN         NaN  ...   \n",
            "1999     NaN  BAR0813AU      NaN         NaN        NaN         NaN  ...   \n",
            "\n",
            "      BIC Of Transfer Agent  Domicile Of Transfer Agent  Marketmaker Name  \\\n",
            "0                       NaN                         NaN               NaN   \n",
            "1                       NaN                         NaN               NaN   \n",
            "2                       NaN                         NaN               NaN   \n",
            "3                       NaN                         NaN               NaN   \n",
            "4                       NaN                         NaN               NaN   \n",
            "...                     ...                         ...               ...   \n",
            "1995            NDEALUL2XXX                          LU               NaN   \n",
            "1996            NDEALUL2XXX                          LU               NaN   \n",
            "1997                    NaN                         NaN               NaN   \n",
            "1998                    NaN                         NaN               NaN   \n",
            "1999                    NaN                         NaN               NaN   \n",
            "\n",
            "      Dissemination Recipient  \\\n",
            "0                         NaN   \n",
            "1                         NaN   \n",
            "2                         NaN   \n",
            "3                         NaN   \n",
            "4                         NaN   \n",
            "...                       ...   \n",
            "1995                      NaN   \n",
            "1996                      NaN   \n",
            "1997                      NaN   \n",
            "1998                      NaN   \n",
            "1999                      NaN   \n",
            "\n",
            "      Global Intermediary Identification Number Of Fund  \\\n",
            "0                                   BI33Z7.99999.SL.040   \n",
            "1                                   BI33Z7.99999.SL.040   \n",
            "2                                   I5ACQV.99999.SL.040   \n",
            "3                                   I5ACQV.99999.SL.040   \n",
            "4                                   U5QQTP.99999.SL.040   \n",
            "...                                                 ...   \n",
            "1995                                0H5GAA.99999.SL.442   \n",
            "1996                                0H5GAA.99999.SL.442   \n",
            "1997                                                NaN   \n",
            "1998                                                NaN   \n",
            "1999                                                NaN   \n",
            "\n",
            "      Sub-Investment Advisor Name  \\\n",
            "0                             NaN   \n",
            "1                             NaN   \n",
            "2                             NaN   \n",
            "3                             NaN   \n",
            "4                             NaN   \n",
            "...                           ...   \n",
            "1995                          NaN   \n",
            "1996                          NaN   \n",
            "1997                          NaN   \n",
            "1998                          NaN   \n",
            "1999                          NaN   \n",
            "\n",
            "                                           Auditor Name  \\\n",
            "0                                     KPMG Austria GmbH   \n",
            "1                                     KPMG Austria GmbH   \n",
            "2                                     KPMG Austria GmbH   \n",
            "3                                     KPMG Austria GmbH   \n",
            "4                                     KPMG Austria GmbH   \n",
            "...                                                 ...   \n",
            "1995  PricewaterhouseCoopers, 2 rue Gerhard Mercator...   \n",
            "1996  PricewaterhouseCoopers, 2 rue Gerhard Mercator...   \n",
            "1997                                                NaN   \n",
            "1998                                                NaN   \n",
            "1999                                                NaN   \n",
            "\n",
            "                Fund Promoter Name  EmailAddressOfManCoIdentifier  \\\n",
            "0                         Kathrein                            NaN   \n",
            "1                         Kathrein                            NaN   \n",
            "2                              NaN                            NaN   \n",
            "3                              NaN                            NaN   \n",
            "4                              NaN                            NaN   \n",
            "...                            ...                            ...   \n",
            "1995  Nordea Investment Funds S.A.                            NaN   \n",
            "1996  Nordea Investment Funds S.A.                            NaN   \n",
            "1997                           NaN                            NaN   \n",
            "1998                           NaN                            NaN   \n",
            "1999                           NaN                            NaN   \n",
            "\n",
            "      IsUNPRISignatoryIdentifier  \n",
            "0                            NaN  \n",
            "1                            NaN  \n",
            "2                            NaN  \n",
            "3                            NaN  \n",
            "4                            NaN  \n",
            "...                          ...  \n",
            "1995                         NaN  \n",
            "1996                         NaN  \n",
            "1997                         NaN  \n",
            "1998                         NaN  \n",
            "1999                         NaN  \n",
            "\n",
            "[2000 rows x 2206 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"primeiras linhas do dataframe\")\n",
        "\n",
        "# Definindo o tamanho do chunk para x linhas\n",
        "chunksize = 2000\n",
        "reader = pd.read_csv('Quali_20240601.csv', chunksize=chunksize)\n",
        "\n",
        "# Pegando o primeiro chunk\n",
        "chunk = next(reader)\n",
        "\n",
        "# Exibindo o chunk\n",
        "print(chunk)\n",
        "\n",
        "#cédula responsável por separar uma parte (um chunk) do CSV selecionado de acordo com um tamanho inserido manualmente e o exibir\n",
        "#mais vantajoso pois não carrega o arquivo todo, separa apenas uma AMOSTRA\n",
        "# o que exige menos poder computacional e checa a funcionabilidade para um grupo seleto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Legal Fund Name Including Umbrella', 'Fund Code', 'Citi Code', 'ISIN', 'WKN', '20000_Financial_Instrument_Identifying_Data', 'EPT Portfolio Name', 'EPT Portfolio or Share Class Currency', 'EPT PRIIPs KID Publication Date', 'EPT Reference Language', 'EPT Valuation Frequency', 'EPT Summary Risk Indicator', 'EPT Is SRI Adjusted', 'EPT Market Risk Measure', 'EPT Credit Risk Measure', 'EPT Recommended Holding Period', 'EPT Number Of Observed Returns', 'EPT Reference Invested Amount', 'EPT Ongoing Costs Management Fees and Other Administrative or Operating Costs', 'EPT Portfolio Transaction Costs', 'EPT Target Market Retail Investor Type', 'EPT Investment Objective', 'EPT Risk Narrative', 'EPT Other Risk Narrative', 'EPT Investment Option', 'Portfolio Turnover Ratio', 'Portfolio Turnover Ratio Date', 'FE Group Name', 'Unit Status', 'Company Contact Address', 'Company Contact E-Mail', 'Company Contact Post Code', 'Company Contact Telephone', 'Company Contact Web Address', 'FE Fund Name', 'Sub Category', 'Main Category', 'Global Fund Classification', 'Has Performance Fee', 'Performance Fee Applied', 'Custodian Fee Applied', 'Subscription Fee Maximum', 'Redemption Fee Maximum', 'Management Fee Applied', 'Management Fee Applied Reference Date', 'Management Fee Maximum', 'TER Excluding Performance Fee', 'TER Excluding Performance Fee Date', 'TER Including Performance Fee', 'TER Including Performance Fee Date', 'Has Ongoing Charges', 'Ongoing Charges', 'Ongoing Charges Date', 'Distribution Fee', 'Has Separate Distribution Fee', 'Distribution Fee Reference Date', 'Minimal Subscription Category', 'Minimal Initial Subscription In Shares', 'Minimal Initial Subscription In Amount', 'Currency Of Minimal Subscription', 'Minimal Subsequent Subscription Category', 'Minimal Subsequent Subscription In Shares', 'Minimal Subsequent Subscription In Amount', 'Maximal Number Of Possible Decimals NAV', 'Settlement Period For Subscription', 'EFAMA Main EFC Category', 'EFAMA Active EFC Classification', 'Is EU Directive Relevant', 'Type Of EU Directive', 'UCITS Version', 'Legal Form', 'Launch Price', 'Launch Price Currency', 'Launch Price Date', 'Listing Currency', 'Valor', 'Share Class Extension', 'Full Share Class Name', 'Abbreviated Share Class Name', 'Valuation Frequency', 'Share Class Distribution Policy', 'Share Class Currency', 'Share Class Lifecycle', 'Share Class Launch Date', 'Investment Status', 'Benchmark', 'SRRI', 'Record Date For SRRI', 'CurrencyHedgeShareClassIdentifier', 'DistributionDeclarationFrequencyIdentifier', 'Asset Class', 'Sector Names', 'Fund Domicile Alpha-2', 'Legal Fund Name Only', 'Fund Launch Date', 'Investment Objective in English', 'Fund Currency', 'Open-ended Or Closed-ended Fund Structure', 'CurrencyHedgePortfolioIdentifier', 'Domicile', 'Has Umbrella', 'Umbrella', 'Domicile Of Umbrella', 'Fund Group Name', 'ManCo', 'Domicile Of ManCo', 'Fund Administrator Name', 'Custodian Bank Name', 'Portfolio Managing Company Name', 'Transfer Agent Name', 'Auditor Name', 'Fund Promoter Name', 'Exit Charge', 'Is ETF']\n"
          ]
        }
      ],
      "source": [
        "with open(\"colunas_especificas.txt\", 'r') as fin:\n",
        "    cols = fin.readlines()\n",
        "    cols_especificas = []\n",
        "    for c in cols:\n",
        "        cols_especificas.append(c.replace(\"\\n\",\"\"))\n",
        "\n",
        "\n",
        "print(cols_especificas)\n",
        "\n",
        "#separa as colunas específicas que devem ser analisadas para o caso de haver alteração\n",
        "#faz isso abrindo o arquivo em txt com cada uma e as insere numa lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lendo o arquivo Quali_20240601.csv, limitando a 100 linhas\n",
            "Total de 100 linhas processadas para o arquivo Quali_20240601.csv\n",
            "Lendo o arquivo Quali_20240602.csv, limitando a 100 linhas\n",
            "Total de 100 linhas processadas para o arquivo Quali_20240602.csv\n",
            "Lendo o arquivo Quali_20240603.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240603.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240604.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240604.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240605.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240605.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240606.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240606.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240607.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240607.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240608.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240608.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240609.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240609.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240610.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240610.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240611.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240611.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240612.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240612.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240613.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240613.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240614.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240614.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240615.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240615.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240616.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240616.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240617.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240617.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240618.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240618.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240619.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240619.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240620.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240620.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240621.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240621.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240622.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240622.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240623.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240623.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240624.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240624.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240625.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240625.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240626.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240626.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240627.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240627.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240628.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240628.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240629.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240629.csv não foi encontrado. Pulando para o próximo arquivo.\n",
            "Lendo o arquivo Quali_20240630.csv, limitando a 100 linhas\n",
            "O arquivo Quali_20240630.csv não foi encontrado. Pulando para o próximo arquivo.\n"
          ]
        }
      ],
      "source": [
        "# Defina o tamanho do chunk para ler um número específico de linhas\n",
        "nrows_to_read = 100  # Número específico de linhas a serem lidas de cada arquivo\n",
        "\n",
        "# Dicionário para armazenar os DataFrames processados e a contagem de linhas\n",
        "chunks_dict = {}\n",
        "total_lines_dict = {}  # Novo dicionário para armazenar o número total de linhas\n",
        "\n",
        "for xx in range(1, 31):\n",
        "    # Formatar o número com dois dígitos\n",
        "    xx_formatted = f\"{xx:02d}\"\n",
        "    filename = f\"Quali_202406{xx_formatted}.csv\"\n",
        "    \n",
        "    print(f\"Lendo o arquivo {filename}, limitando a {nrows_to_read} linhas\")\n",
        "    \n",
        "    try:\n",
        "        # Ler apenas um número específico de linhas do arquivo atual\n",
        "        chunk = pd.read_csv(filename, nrows=nrows_to_read)\n",
        "        \n",
        "        # Somar o número de linhas lidas no chunk atual\n",
        "        total_lines = len(chunk)\n",
        "        \n",
        "        # Verificar quais colunas estão presentes no chunk\n",
        "        cols_to_keep = [col for col in cols_especificas if col in chunk.columns]\n",
        "        \n",
        "        # Se nenhuma coluna for encontrada, pular o arquivo\n",
        "        if not cols_to_keep:\n",
        "            print(f\"Nenhuma das colunas especificadas foi encontrada em {filename}\")\n",
        "            continue\n",
        "        \n",
        "        # Filtrar as colunas específicas\n",
        "        chunk_filtered = chunk[cols_to_keep]\n",
        "        \n",
        "        # Armazenar o chunk filtrado no dicionário\n",
        "        chunks_dict[f\"chunk_{xx_formatted}\"] = chunk_filtered\n",
        "        \n",
        "        # Armazenar o número total de linhas lidas para o arquivo atual\n",
        "        total_lines_dict[f\"file_{xx_formatted}\"] = total_lines\n",
        "        print(f\"Total de {total_lines} linhas processadas para o arquivo {filename}\")\n",
        "    \n",
        "    except FileNotFoundError:\n",
        "        print(f\"O arquivo {filename} não foi encontrado. Pulando para o próximo arquivo.\")\n",
        "        continue\n",
        "\n",
        "# Agora você pode acessar o número total de linhas processadas para cada arquivo\n",
        "# Por exemplo, para o arquivo do dia 01 de junho:\n",
        "# print(total_lines_dict['file_01'])\n",
        "\n",
        "\n",
        "# nessa cédula, é passado um número específico de linhas para serem lidas de cada um dos arquivos de 1 a 30 (dias de junho)\n",
        "# para cada arquivo, separa as colunas específicas armazena o dataframe resultante num dicionário e conta o número de linhas lidas\n",
        "# se não for detectado um arquivo, ele pula pro próximo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Legal Fund Name Including Umbrella', 'Fund Code', 'Citi Code', 'ISIN',\n",
            "       'WKN', '20000_Financial_Instrument_Identifying_Data',\n",
            "       'EPT Portfolio Name', 'EPT Portfolio or Share Class Currency',\n",
            "       'EPT PRIIPs KID Publication Date', 'EPT Reference Language',\n",
            "       ...\n",
            "       'ManCo', 'Domicile Of ManCo', 'Fund Administrator Name',\n",
            "       'Custodian Bank Name', 'Portfolio Managing Company Name',\n",
            "       'Transfer Agent Name', 'Auditor Name', 'Fund Promoter Name',\n",
            "       'Exit Charge', 'Is ETF'],\n",
            "      dtype='object', length=114)\n"
          ]
        }
      ],
      "source": [
        "df_chunk_01 = chunks_dict['chunk_01']\n",
        "print(df_chunk_01.columns)\n",
        "\n",
        "#printa as colunas existentes em cada chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Supondo que você já tem o dicionário 'chunks_dict' com os DataFrames para cada dia\n",
        "# E que as colunas identificadoras são 'ISIN', 'Citi Code', 'EPT Reference Language'\n",
        "\n",
        "# Lista para armazenar os DataFrames com a coluna 'data' adicionada\n",
        "dfs_with_date = []\n",
        "\n",
        "for xx in range(1, 31):\n",
        "    xx_formatted = f\"{xx:02d}\"\n",
        "    key = f\"chunk_{xx_formatted}\"\n",
        "    if key in chunks_dict:\n",
        "        df = chunks_dict[key].copy()\n",
        "        \n",
        "        # Adiciona a coluna 'data' com o valor do dia no formato 'xx/06/2024'\n",
        "        df['data'] = f\"{xx_formatted}/06/2024\"\n",
        "        dfs_with_date.append(df)\n",
        "\n",
        "# Combina todos os DataFrames em um único DataFrame\n",
        "combined_df = pd.concat(dfs_with_date, ignore_index=True)\n",
        "\n",
        "# Remove as linhas que possuem valores NaN\n",
        "combined_df.dropna(inplace=True)\n",
        "\n",
        "# Ordena o DataFrame pelos identificadores e pela data\n",
        "combined_df.sort_values(by=['ISIN', 'Citi Code', 'EPT Reference Language', 'data'], inplace=True)\n",
        "\n",
        "# Lista para armazenar as mudanças detectadas\n",
        "changes = []\n",
        "\n",
        "# Definir as colunas identificadoras e as colunas a serem comparadas\n",
        "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
        "value_cols = [col for col in combined_df.columns if col not in id_cols + ['data']]\n",
        "\n",
        "# Agrupa o DataFrame pelos identificadores\n",
        "grouped = combined_df.groupby(id_cols)\n",
        "\n",
        "for name, group in grouped:\n",
        "    group = group.sort_values(by='data')\n",
        "    group = group.reset_index(drop=True)\n",
        "    for i in range(1, len(group)):\n",
        "        current_row = group.loc[i]\n",
        "        previous_row = group.loc[i-1]\n",
        "        data_current = current_row['data']  # Data do valor novo\n",
        "        data_previous = previous_row['data']  # Data do valor antigo\n",
        "        for col in value_cols:\n",
        "            value_current = current_row[col]\n",
        "            value_previous = previous_row[col]\n",
        "            # Verifica se os valores são diferentes, considerando valores nulos\n",
        "            if pd.isnull(value_current) and pd.isnull(value_previous):\n",
        "                continue  # Ambos são nulos, não há mudança\n",
        "            elif value_current != value_previous:\n",
        "                changes.append({\n",
        "                    'ISIN': current_row['ISIN'],\n",
        "                    'Citi Code': current_row['Citi Code'],\n",
        "                    'EPT Reference Language': current_row['EPT Reference Language'],\n",
        "                    'campo': col,\n",
        "                    'valor_antigo': value_previous,\n",
        "                    'valor_novo': value_current,\n",
        "                    'data_antigo': data_previous,\n",
        "                    'data_novo': data_current\n",
        "                })\n",
        "\n",
        "# Cria um DataFrame com as mudanças\n",
        "changes_df = pd.DataFrame(changes)\n",
        "\n",
        "# Exibe o DataFrame com as mudanças\n",
        "print(changes_df)\n",
        "\n",
        "#lê dados dos dataframes armazenados nos dicionários e "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleciona apenas as colunas desejadas e imprime o DataFrame\n",
        "#print(changes_df[['campo', 'valor_antigo', 'valor_novo', 'data']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          campo  valor_antigo    valor_novo  \\\n",
            "0   20000_Financial_Instrument_Identifying_Data  AT0000691365           NaN   \n",
            "21  20000_Financial_Instrument_Identifying_Data  LU0289214545           NaN   \n",
            "3   20000_Financial_Instrument_Identifying_Data  AT0000704366           NaN   \n",
            "18  20000_Financial_Instrument_Identifying_Data  IE00B61TKZ25           NaN   \n",
            "6   20000_Financial_Instrument_Identifying_Data  AT0000721402           NaN   \n",
            "9   20000_Financial_Instrument_Identifying_Data  AT0000779392           NaN   \n",
            "15  20000_Financial_Instrument_Identifying_Data  AT0000A0FA24           NaN   \n",
            "12  20000_Financial_Instrument_Identifying_Data  AT0000A0F9X2           NaN   \n",
            "20  20000_Financial_Instrument_Identifying_Data  IE00B61TKZ25           NaN   \n",
            "19  20000_Financial_Instrument_Identifying_Data           NaN  IE00B61TKZ25   \n",
            "17  20000_Financial_Instrument_Identifying_Data  AT0000A0FA24           NaN   \n",
            "16  20000_Financial_Instrument_Identifying_Data           NaN  AT0000A0FA24   \n",
            "14  20000_Financial_Instrument_Identifying_Data  AT0000A0F9X2           NaN   \n",
            "11  20000_Financial_Instrument_Identifying_Data  AT0000779392           NaN   \n",
            "22  20000_Financial_Instrument_Identifying_Data           NaN  LU0289214545   \n",
            "10  20000_Financial_Instrument_Identifying_Data           NaN  AT0000779392   \n",
            "8   20000_Financial_Instrument_Identifying_Data  AT0000721402           NaN   \n",
            "7   20000_Financial_Instrument_Identifying_Data           NaN  AT0000721402   \n",
            "5   20000_Financial_Instrument_Identifying_Data  AT0000704366           NaN   \n",
            "4   20000_Financial_Instrument_Identifying_Data           NaN  AT0000704366   \n",
            "2   20000_Financial_Instrument_Identifying_Data  AT0000691365           NaN   \n",
            "1   20000_Financial_Instrument_Identifying_Data           NaN  AT0000691365   \n",
            "13  20000_Financial_Instrument_Identifying_Data           NaN  AT0000A0F9X2   \n",
            "23  20000_Financial_Instrument_Identifying_Data  LU0289214545           NaN   \n",
            "\n",
            "          data  \n",
            "0   01/06/2024  \n",
            "21  01/06/2024  \n",
            "3   01/06/2024  \n",
            "18  01/06/2024  \n",
            "6   01/06/2024  \n",
            "9   01/06/2024  \n",
            "15  01/06/2024  \n",
            "12  01/06/2024  \n",
            "20  02/06/2024  \n",
            "19  02/06/2024  \n",
            "17  02/06/2024  \n",
            "16  02/06/2024  \n",
            "14  02/06/2024  \n",
            "11  02/06/2024  \n",
            "22  02/06/2024  \n",
            "10  02/06/2024  \n",
            "8   02/06/2024  \n",
            "7   02/06/2024  \n",
            "5   02/06/2024  \n",
            "4   02/06/2024  \n",
            "2   02/06/2024  \n",
            "1   02/06/2024  \n",
            "13  02/06/2024  \n",
            "23  02/06/2024  \n"
          ]
        }
      ],
      "source": [
        "# Supondo que você já tem o dicionário 'chunks_dict' com os DataFrames para cada dia\n",
        "# E que as colunas identificadoras são 'ISIN', 'Citi Code', 'EPT Reference Language'\n",
        "\n",
        "# Lista para armazenar os DataFrames com a coluna 'data' adicionada\n",
        "dfs_with_date = []\n",
        "\n",
        "for xx in range(1, 31):\n",
        "    xx_formatted = f\"{xx:02d}\"\n",
        "    key = f\"chunk_{xx_formatted}\"\n",
        "    if key in chunks_dict:\n",
        "        df = chunks_dict[key].copy()\n",
        "        # Adiciona a coluna 'data' com o valor do dia no formato 'xx/06/2024'\n",
        "        df['data'] = f\"{xx_formatted}/06/2024\"\n",
        "        dfs_with_date.append(df)\n",
        "\n",
        "# Combina todos os DataFrames em um único DataFrame\n",
        "combined_df = pd.concat(dfs_with_date, ignore_index=True)\n",
        "\n",
        "# Converter a coluna 'data' para datetime para facilitar a ordenação\n",
        "combined_df['data'] = pd.to_datetime(combined_df['data'], format='%d/%m/%Y')\n",
        "\n",
        "# Ordena o DataFrame pelos identificadores e pela data\n",
        "combined_df.sort_values(by=['ISIN', 'Citi Code', 'EPT Reference Language', 'data'], inplace=True)\n",
        "\n",
        "# Lista para armazenar as mudanças detectadas\n",
        "changes = []\n",
        "\n",
        "# Definir as colunas identificadoras e as colunas a serem comparadas\n",
        "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
        "value_cols = [col for col in combined_df.columns if col not in id_cols + ['data']]\n",
        "\n",
        "# Agrupa o DataFrame pelos identificadores\n",
        "grouped = combined_df.groupby(id_cols)\n",
        "\n",
        "for name, group in grouped:\n",
        "    group = group.sort_values(by='data')\n",
        "    group = group.reset_index(drop=True)\n",
        "    for i in range(1, len(group)):\n",
        "        current_row = group.loc[i]\n",
        "        previous_row = group.loc[i-1]\n",
        "        data_current = current_row['data'].strftime('%d/%m/%Y')  # Converte para string no formato desejado\n",
        "        data_previous = previous_row['data'].strftime('%d/%m/%Y')\n",
        "        for col in value_cols:\n",
        "            value_current = current_row[col]\n",
        "            value_previous = previous_row[col]\n",
        "            # Verifica se os valores são diferentes, considerando valores nulos\n",
        "            if pd.isnull(value_current) and pd.isnull(value_previous):\n",
        "                continue  # Ambos são nulos, não há mudança\n",
        "            elif pd.isnull(value_current) != pd.isnull(value_previous):\n",
        "                # Um valor é nulo e o outro não\n",
        "                changes.append({\n",
        "                    'campo': col,\n",
        "                    'valor_antigo': value_previous,\n",
        "                    'valor_novo': value_current,\n",
        "                    'data': data_current\n",
        "                })\n",
        "            elif value_current != value_previous:\n",
        "                changes.append({\n",
        "                    'campo': col,\n",
        "                    'valor_antigo': value_previous,\n",
        "                    'valor_novo': value_current,\n",
        "                    'data': data_current\n",
        "                })\n",
        "\n",
        "# Cria um DataFrame com as mudanças\n",
        "changes_df = pd.DataFrame(changes)\n",
        "\n",
        "# Seleciona apenas as colunas desejadas\n",
        "changes_df = changes_df[['campo', 'valor_antigo', 'valor_novo', 'data']]\n",
        "\n",
        "# Converter a coluna 'data' para datetime para ordenação\n",
        "changes_df['data'] = pd.to_datetime(changes_df['data'], format='%d/%m/%Y')\n",
        "\n",
        "# Ordena o DataFrame 'changes_df' pela coluna 'data'\n",
        "changes_df.sort_values(by='data', inplace=True)\n",
        "\n",
        "# Opcional: Converte a coluna 'data' de volta para string no formato desejado\n",
        "changes_df['data'] = changes_df['data'].dt.strftime('%d/%m/%Y')\n",
        "\n",
        "# Salva o DataFrame 'changes_df' em um arquivo CSV\n",
        "changes_df.to_csv('mudancas_detectadas.csv', index=False)\n",
        "\n",
        "# Exibe o DataFrame com as mudanças ordenadas por data\n",
        "print(changes_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          data\n",
            "0   01/06/2024\n",
            "21  01/06/2024\n",
            "3   01/06/2024\n",
            "18  01/06/2024\n",
            "6   01/06/2024\n",
            "9   01/06/2024\n",
            "15  01/06/2024\n",
            "12  01/06/2024\n",
            "20  02/06/2024\n",
            "19  02/06/2024\n",
            "17  02/06/2024\n",
            "16  02/06/2024\n",
            "14  02/06/2024\n",
            "11  02/06/2024\n",
            "22  02/06/2024\n",
            "10  02/06/2024\n",
            "8   02/06/2024\n",
            "7   02/06/2024\n",
            "5   02/06/2024\n",
            "4   02/06/2024\n",
            "2   02/06/2024\n",
            "1   02/06/2024\n",
            "13  02/06/2024\n",
            "23  02/06/2024\n"
          ]
        }
      ],
      "source": [
        "print(changes_df[['data']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
