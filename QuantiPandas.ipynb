{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versão Antiga do Quanti Concatenando todos os csvs em um só com o pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Foi alterado para parquet para melhorar a performance com processamento paralelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "import sqlalchemy as db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arquivos = 30\n",
    "\n",
    "# Criar uma lista vazia para armazenar os DataFrames\n",
    "dados_fundos = []\n",
    "\n",
    "\n",
    "for i in range(n_arquivos):\n",
    "    \n",
    "    # Carregar o CSV em um DataFrame\n",
    "    df = pd.read_csv(f\"Quanti_202406{i+1:02d}.csv\")\n",
    "    \n",
    "    \n",
    "    # Adicionar o DataFrame à lista\n",
    "    dados_fundos.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "dados_concatenados = pd.concat(dados_fundos, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ISIN', 'AuM Fund', 'AuM Fund Date', 'AuM Share Class',\n",
       "       'AuM Share Class Date', 'Bid NAV', 'Bid NAV Date', 'Ask NAV',\n",
       "       'Ask NAV Date', 'Valuation NAV', 'Valuation NAV Date',\n",
       "       'Transaction NAV', 'Transaction NAV Date', 'NoS Fund Date',\n",
       "       'NoS Share Class', 'NoS Share Class Date', 'NoS Fund', 'FE Bid',\n",
       "       'FE Bid Date', 'FE Offer', 'FE Offer Date', 'FE NAV', 'FE NAV Date',\n",
       "       'FE Generic NAV', 'FE Generic NAV Date', 'FE AUM Fund Date',\n",
       "       'FE AUM Share Class', 'FE AUM Share Class Date', 'FE NOS Fund',\n",
       "       'FE NOS Fund Date', 'FE NOS Share Class', 'FE NOS Share Class Date',\n",
       "       'Citi Code', 'Fund Code', 'Dynamic Currency', 'FE AUM Fund', 'FE Mid',\n",
       "       'FE Mid Date', 'FE Total Return NAV', 'FE Total Return NAV Date',\n",
       "       'Amount of Shares Redeemed Fund',\n",
       "       'Amount of Shares Redeemed Share Class',\n",
       "       'Amount of Shares Subscribed Fund',\n",
       "       'Amount of Shares Subscribed Share Class',\n",
       "       'Number of Shares Redeemed Fund',\n",
       "       'Number of Shares Redeemed Share Class',\n",
       "       'Number of Shares Subscribed Fund',\n",
       "       'Number of Shares Subscribed Share Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_concatenados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_concatenados = dados_concatenados.dropna(subset=[\"ISIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prioritário\n",
    "df1 = dados_concatenados[[\"ISIN\",\"Valuation NAV\",\"Valuation NAV Date\"]].sort_values(by=[\"ISIN\",\"Valuation NAV Date\"])\n",
    "df2 = dados_concatenados[[\"ISIN\",\"FE Bid\",'FE Bid Date']].sort_values(by=[\"ISIN\",\"FE Bid Date\"])\n",
    "df3 = dados_concatenados[[\"ISIN\",\"FE Generic NAV\",\"FE Generic NAV Date\"]].sort_values(by=[\"ISIN\",\"FE Generic NAV Date\"])\n",
    "df4 = dados_concatenados[[\"ISIN\",\"FE NAV\",\"FE NAV Date\"]].sort_values(by=[\"ISIN\",\"FE NAV Date\"])\n",
    "df5 = dados_concatenados[[\"ISIN\",\"Transaction NAV\",\"Transaction NAV Date\"]].sort_values(by=[\"ISIN\",\"Transaction NAV Date\"])\n",
    "fields = [\"Valuation NAV\",\"FE BID\",\"FE Generic NAV\",\"FE NAV\",\"Transaction NAV\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extras\n",
    "df6 = dados_concatenados[[\"ISIN\",\"AuM Fund\",\"AuM Fund Date\"]].sort_values(by=[\"ISIN\",\"AuM Fund Date\"]),\n",
    "df7 = dados_concatenados[[\"ISIN\",\"AuM Share Class\",\"AuM Share Class Date\"]].sort_values(by=[\"ISIN\",\"AuM Share Class Date\"]),\n",
    "df8 = dados_concatenados[[\"ISIN\",\"Ask NAV\",\"Ask NAV Date\"]].sort_values(by=[\"ISIN\",\"Ask NAV Date\"]),\n",
    "df9 = dados_concatenados[[\"ISIN\",\"Bid NAV\",\"Bid NAV Date\"]].sort_values(by=[\"ISIN\",\"Bid NAV Date\"]),\n",
    "df10 = dados_concatenados[[\"ISIN\",\"NoS Fund\",\"NoS Fund Date\"]].sort_values(by=[\"ISIN\",\"NoS Fund Date\"]),\n",
    "df11 = dados_concatenados[[\"ISIN\",\"NoS Share Class\",\"NoS Share Class Date\"]].sort_values(by=[\"ISIN\",\"NoS Share Class Date\"]),\n",
    "df12 = dados_concatenados[[\"ISIN\",\"FE Offer\",\"FE Offer Date\"]].sort_values(by=[\"ISIN\",\"FE Offer Date\"]),\n",
    "df13 = dados_concatenados[[\"ISIN\",\"FE AUM Fund\",\"FE AUM Fund Date\"]].sort_values(by=[\"ISIN\",\"FE AUM Fund Date\"]),\n",
    "df14 = dados_concatenados[[\"ISIN\",\"FE AUM Share Class\",\"FE AUM Share Class Date\"]].sort_values(by=[\"ISIN\",\"FE AUM Share Class Date\"]),\n",
    "df15 = dados_concatenados[[\"ISIN\",\"FE NOS Fund\",\"FE NOS Fund Date\"]].sort_values(by=[\"ISIN\",\"FE NOS Fund Date\"]),\n",
    "df16 = dados_concatenados[[\"ISIN\",\"FE NOS Share Class\",\"FE NOS Share Class Date\"]].sort_values(by=[\"ISIN\",\"FE NOS Share Class Date\"]),\n",
    "\n",
    "fields = [\"Valuation NAV\",\"FE BID\",\"FE Generic NAV\",\"FE NAV\",\"Transaction NAV\",\"AuM Fund\",\"AuM Share Class\",\"Ask NAV\",\n",
    "          \"Bid NAV\",\"NoS Fund\",\"NoS Share Class\",\"FE Offer\",\"FE AUM Fund\",\"FE AUM Share Class\",\"FE NOS Fund\",\"FE NOS Share Class\"],\n",
    "ldf = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "isins = dados_concatenados[\"ISIN\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = [df1,df2,df3,df4,df5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"ISIN\",\"data_valor_antigo\",\"data_valor_novo\",\"campo\",\"valor antigo\",\"valor novo\" ]\n",
    "new_df = pd.DataFrame(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_16372\\3890616267.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[1] != next_row[1]:\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_16372\\3890616267.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"data_valor_antigo\": row[2],\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_16372\\3890616267.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"data_valor_novo\": next_row[2],\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_16372\\3890616267.py:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"valor_antigo\": row[1],\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_16372\\3890616267.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"valor_novo\": next_row[1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m ldf:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m isin \u001b[38;5;129;01min\u001b[39;00m isins:\n\u001b[1;32m----> 9\u001b[0m         actual \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISIN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m isin]\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(actual) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     12\u001b[0m             row \u001b[38;5;241m=\u001b[39m actual\u001b[38;5;241m.\u001b[39miloc[j]\n",
      "File \u001b[1;32mc:\\Users\\thiag\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\Users\\thiag\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[1;32mc:\\Users\\thiag\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\thiag\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\thiag\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inicializa a lista de DataFrames e outras variáveis\n",
    "campo = 0\n",
    "new_df_list = []  # Lista para armazenar os DataFrames temporários\n",
    "\n",
    "for df in ldf:\n",
    "    for isin in isins:\n",
    "        actual = df[df[\"ISIN\"] == isin]\n",
    "\n",
    "        for j in range(len(actual) - 1):\n",
    "            row = actual.iloc[j]\n",
    "            next_row = actual.iloc[j + 1]\n",
    "            if row[1] != next_row[1]:\n",
    "                new_df_list.append({\n",
    "                    \"ISIN\": row[\"ISIN\"],\n",
    "                    \"campo\": fields[campo],\n",
    "                    \"data_valor_antigo\": row[2],\n",
    "                    \"data_valor_novo\": next_row[2],\n",
    "                    \"valor_antigo\": row[1],\n",
    "                    \"valor_novo\": next_row[1]\n",
    "                })\n",
    "\n",
    "    campo += 1\n",
    "\n",
    "# Concatena todos os dicionários em um único DataFrame\n",
    "new_df = pd.DataFrame(new_df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'localhost'\n",
    "database = 'master'\n",
    "db.create_engine(f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server;Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server;Trusted_Connection=yes;')\n",
    "df.to_sql('Quali', con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular as mudanças diárias para a coluna 'valor_ativo', por exemplo\n",
    "dados_concatenados['mudanca_valor_ativo'] = dados_concatenados.groupby('ISIN')['valor_ativo'].diff()\n",
    "\n",
    "# Filtrar apenas as linhas onde houveram mudanças\n",
    "mudancas_diarias = dados_concatenados[dados_concatenados['mudanca_valor_ativo'].notnull()]\n",
    "\n",
    "# Mostrar as primeiras linhas do resultado\n",
    "print(mudancas_diarias.head())\n",
    "\n",
    "# Se desejar salvar as mudanças em um novo arquivo CSV para análise\n",
    "mudancas_diarias.to_csv('mudancas_diarias_fundos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
