{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ler a lista de colunas específicas do arquivo 'colunas_especificas.txt'\n",
    "with open(\"colunas_especificas.txt\", 'r') as fin:\n",
    "    cols = fin.readlines()\n",
    "    cols_especificas = [c.strip() for c in cols]\n",
    "\n",
    "# Defina as colunas para ordenação\n",
    "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
    "\n",
    "# Combine as colunas necessárias para leitura (evita ler colunas desnecessárias)\n",
    "cols_to_read = cols_especificas + [col for col in id_cols if col not in cols_especificas]\n",
    "\n",
    "# Definir o tamanho do chunk (número de linhas a serem lidas)\n",
    "# Se chunk_size for None, o script lerá o arquivo inteiro\n",
    "chunk_size = 1000  # Defina para um número inteiro, por exemplo, 1000, para ler apenas 1000 linhas\n",
    "\n",
    "for xx in range(1, 31):\n",
    "    xx_formatted = f\"{xx:02d}\"\n",
    "    input_filename = f\"Quali_202406{xx_formatted}.csv\"\n",
    "    output_filename = f\"prio_{xx_formatted}_sorted.csv\"\n",
    "\n",
    "    try:\n",
    "        if chunk_size is not None:\n",
    "            # Ler apenas as primeiras 'chunk_size' linhas\n",
    "            df = pd.read_csv(input_filename, usecols=cols_to_read, nrows=chunk_size)\n",
    "        else:\n",
    "            # Ler o arquivo inteiro\n",
    "            df = pd.read_csv(input_filename, usecols=cols_to_read)\n",
    "\n",
    "        # Verificar se as colunas de ordenação estão presentes\n",
    "        missing_cols = [col for col in id_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"As seguintes colunas para ordenação estão ausentes no arquivo {input_filename}: {missing_cols}\")\n",
    "            continue\n",
    "\n",
    "        # Ordenar o DataFrame pelas colunas especificadas\n",
    "        df_sorted = df.sort_values(by=id_cols)\n",
    "\n",
    "        # Salvar o DataFrame filtrado e ordenado em um novo arquivo CSV\n",
    "        df_sorted.to_csv(output_filename, index=False)\n",
    "\n",
    "        print(f\"Arquivo '{output_filename}' salvo com sucesso.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"O arquivo '{input_filename}' não foi encontrado. Pulando para o próximo arquivo.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao processar o arquivo '{input_filename}': {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Defina as colunas identificadoras\n",
    "id_cols = ['ISIN', 'Citi Code', 'EPT Reference Language']\n",
    "\n",
    "# Lista para armazenar os DataFrames com a coluna 'data' adicionada\n",
    "dfs_with_date = []\n",
    "\n",
    "total_chunks = 30  # Total de chunks a serem processados\n",
    "\n",
    "for xx in range(1, total_chunks + 1):\n",
    "    xx_formatted = f\"{xx:02d}\"\n",
    "    filename = f\"prio_{xx_formatted}_sorted.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Ler o arquivo 'prio_xx_sorted.csv'\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Adiciona a coluna 'data' com o valor do dia no formato 'xx/06/2024'\n",
    "        df['data'] = f\"{xx_formatted}/06/2024\"\n",
    "        \n",
    "        # Certifique-se de que as colunas identificadoras estão presentes\n",
    "        missing_cols = [col for col in id_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"\\nAs seguintes colunas estão ausentes no arquivo {filename}: {missing_cols}\")\n",
    "            continue\n",
    "        \n",
    "        dfs_with_date.append(df)\n",
    "        \n",
    "        # Imprimir o progresso e apagar a linha anterior\n",
    "        sys.stdout.write(f\"\\rProcessando chunk {xx} de {total_chunks}\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nO arquivo '{filename}' não foi encontrado. Pulando para o próximo arquivo.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro ao processar o arquivo '{filename}': {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nTodos os chunks foram processados.\")\n",
    "\n",
    "# Combina todos os DataFrames em um único DataFrame\n",
    "combined_df = pd.concat(dfs_with_date, ignore_index=True)\n",
    "\n",
    "# Converter a coluna 'data' para datetime para facilitar a ordenação\n",
    "combined_df['data'] = pd.to_datetime(combined_df['data'], format='%d/%m/%Y')\n",
    "\n",
    "# Ordena o DataFrame pelos identificadores e pela data\n",
    "combined_df.sort_values(by=id_cols + ['data'], inplace=True)\n",
    "\n",
    "# Lista para armazenar as mudanças detectadas\n",
    "changes = []\n",
    "\n",
    "# Definir as colunas a serem comparadas (todas exceto as identificadoras e 'data')\n",
    "value_cols = [col for col in combined_df.columns if col not in id_cols + ['data']]\n",
    "\n",
    "# Agrupa o DataFrame pelos identificadores\n",
    "grouped = combined_df.groupby(id_cols)\n",
    "\n",
    "for name, group in grouped:\n",
    "    group = group.sort_values(by='data').reset_index(drop=True)\n",
    "    for i in range(1, len(group)):\n",
    "        current_row = group.loc[i]\n",
    "        previous_row = group.loc[i - 1]\n",
    "        data_current = current_row['data']\n",
    "        data_previous = previous_row['data']\n",
    "        \n",
    "        # Ignorar mudanças onde a data atual é o primeiro dia\n",
    "        if data_current == pd.to_datetime('01/06/2024', format='%d/%m/%Y'):\n",
    "            continue\n",
    "        \n",
    "        for col in value_cols:\n",
    "            value_current = current_row[col]\n",
    "            value_previous = previous_row[col]\n",
    "            # Verifica se os valores são diferentes, considerando valores nulos\n",
    "            if pd.isnull(value_current) and pd.isnull(value_previous):\n",
    "                continue  # Ambos são nulos, não há mudança\n",
    "            elif pd.isnull(value_current) != pd.isnull(value_previous):\n",
    "                # Um valor é nulo e o outro não\n",
    "                changes.append({\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current.strftime('%d/%m/%Y')\n",
    "                })\n",
    "            elif value_current != value_previous:\n",
    "                changes.append({\n",
    "                    'campo': col,\n",
    "                    'valor_antigo': value_previous,\n",
    "                    'valor_novo': value_current,\n",
    "                    'data': data_current.strftime('%d/%m/%Y')\n",
    "                })\n",
    "\n",
    "print(\"\\nDetecção de mudanças concluída.\")\n",
    "\n",
    "# Cria um DataFrame com as mudanças\n",
    "changes_df = pd.DataFrame(changes)\n",
    "\n",
    "# Converter a coluna 'data' para datetime para ordenação\n",
    "changes_df['data'] = pd.to_datetime(changes_df['data'], format='%d/%m/%Y')\n",
    "\n",
    "# Ordena o DataFrame 'changes_df' pela coluna 'data'\n",
    "changes_df.sort_values(by='data', inplace=True)\n",
    "\n",
    "# Opcional: Converte a coluna 'data' de volta para string no formato desejado\n",
    "changes_df['data'] = changes_df['data'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Seleciona apenas as colunas desejadas\n",
    "changes_df = changes_df[['campo', 'valor_antigo', 'valor_novo', 'data']]\n",
    "\n",
    "# Exibe o DataFrame com as mudanças ordenadas por data\n",
    "print(\"\\nPrimeiras linhas do DataFrame de mudanças:\")\n",
    "print(changes_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
